{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e05d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: If not already installed, install the necessary libraries\n",
    "# pip install shap scikit-learn pandas matplotlib\n",
    "\n",
    "# Step 1: Import Necessary Libraries\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import fetch_california_housing # Using the California housing dataset as an example\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print library versions for reproducibility and debugging\n",
    "print(f\"SHAP version: {shap.__version__}\")\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "\n",
    "# Step 2: Load and Prepare Data\n",
    "print(\"\\n--- Loading and Preparing Data ---\")\n",
    "housing = fetch_california_housing()\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = housing.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set samples: {X_train.shape[0]}\")\n",
    "print(f\"Test set samples: {X_test.shape[0]}\")\n",
    "print(f\"Feature columns: {X_train.columns.tolist()}\")\n",
    "print(\"Data loading and preparation complete.\\n\")\n",
    "\n",
    "# Step 3: Train the Model\n",
    "print(\"--- Training the Model ---\")\n",
    "# Initialize a RandomForestRegressor model with some common parameters\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, min_samples_leaf=5)\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\\n\")\n",
    "\n",
    "# Step 4: Initialize the SHAP Explainer\n",
    "print(\"--- Initializing SHAP Explainer ---\")\n",
    "# shap.Explainer automatically selects an appropriate explainer for the given model.\n",
    "# For tree-based models, it uses TreeExplainer. X_train serves as background data.\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "print(f\"SHAP Explainer type used: {type(explainer)}\") # Should output <class 'shap.explainers._tree.Tree'> or similar\n",
    "print(\"SHAP Explainer initialization complete.\\n\")\n",
    "\n",
    "# Step 5: Calculate SHAP Values\n",
    "print(\"--- Calculating SHAP Values (this may take some time) ---\")\n",
    "# Add check_additivity=False to prevent Additivity check failed errors due to minor floating-point differences.\n",
    "shap_values_obj_test = explainer(X_test, check_additivity=False)\n",
    "\n",
    "print(f\"SHAP values object type: {type(shap_values_obj_test)}\") # Should output <class 'shap._explanation.Explanation'>\n",
    "if hasattr(shap_values_obj_test, 'values'):\n",
    "    print(f\"SHAP values array shape: {shap_values_obj_test.values.shape}\") # (n_samples, n_features)\n",
    "\n",
    "# Get the base value (expected_value)\n",
    "# The Explanation object usually has a base_values attribute.\n",
    "base_value = None # Initialize base_value\n",
    "if hasattr(shap_values_obj_test, 'base_values') and shap_values_obj_test.base_values is not None and len(shap_values_obj_test.base_values) > 0 :\n",
    "    # For single-output regression models, base_values for all samples are typically the same.\n",
    "    base_value = shap_values_obj_test.base_values[0]\n",
    "    if isinstance(base_value, np.ndarray) and base_value.ndim > 0: # If base_values is an array (e.g., multi-output model)\n",
    "        base_value = base_value[0] # Take the base value of the first output\n",
    "    print(f\"Base value (expected_value from Explanation object): {base_value}\")\n",
    "elif hasattr(explainer, 'expected_value'): # As a fallback, get it from the explainer object\n",
    "    base_value = explainer.expected_value\n",
    "    if isinstance(base_value, np.ndarray) and base_value.ndim > 0: # If explainer.expected_value is an array\n",
    "         base_value = base_value[0]\n",
    "    print(f\"Base value (expected_value from explainer): {base_value}\")\n",
    "else:\n",
    "    print(\"Could not retrieve base value (expected_value).\")\n",
    "print(\"SHAP values calculation complete.\\n\")\n",
    "\n",
    "# Step 6: Visualize SHAP Values\n",
    "print(\"--- Generating SHAP Visualizations ---\")\n",
    "\n",
    "# a. Explanation of a Single Prediction (Waterfall Plot)\n",
    "# A waterfall plot shows how features contribute to push the prediction\n",
    "# from the base value (average prediction) to the final predicted value for a single instance.\n",
    "instance_idx = 0 # Choose the first instance in the test set to explain\n",
    "print(f\"\\nExplaining prediction for instance {instance_idx} in the test set:\")\n",
    "plt.figure(figsize=(10, 6)) # Adjust figure size for better readability\n",
    "# shap.plots.waterfall requires a slice of the Explanation object for a single instance\n",
    "shap.plots.waterfall(shap_values_obj_test[instance_idx], show=False)\n",
    "plt.title(f\"SHAP Waterfall Plot for Prediction of Instance {instance_idx}\")\n",
    "plt.tight_layout() # Automatically adjust subplot params for a tight layout\n",
    "plt.show()\n",
    "\n",
    "# b. Global Feature Importance (Bar Plot)\n",
    "# The bar plot shows the mean absolute SHAP value for each feature,\n",
    "# indicating its overall importance to the model.\n",
    "print(\"\\nGlobal Feature Importance (Bar Plot):\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.plots.bar(shap_values_obj_test, show=False)\n",
    "plt.title(\"SHAP Global Feature Importance (Mean Absolute SHAP Value)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# c. Global Feature Insights (Beeswarm Plot / Summary Plot)\n",
    "# The beeswarm plot combines feature importance with feature effects.\n",
    "# Each dot represents a SHAP value for a feature of a specific instance.\n",
    "print(\"\\nGlobal Feature Insights (Beeswarm Plot):\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.plots.beeswarm(shap_values_obj_test, show=False)\n",
    "plt.title(\"SHAP Beeswarm Plot (Feature Importance and Effects)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# d. Feature Dependence Plot (Scatter Plot)\n",
    "# Shows how the value of a single feature affects its SHAP value (impact on prediction).\n",
    "# We'll automatically select the most important feature to plot.\n",
    "# First, calculate the mean absolute SHAP value for each feature.\n",
    "if hasattr(shap_values_obj_test, 'abs') and hasattr(shap_values_obj_test.abs, 'mean'):\n",
    "    mean_abs_shap_values = shap_values_obj_test.abs.mean(0) # Returns an Explanation object or Series\n",
    "    if hasattr(mean_abs_shap_values, 'values') and shap_values_obj_test.feature_names is not None: # If it's an Explanation object\n",
    "        feature_importances = pd.Series(mean_abs_shap_values.values, index=shap_values_obj_test.feature_names)\n",
    "    else: # If it's already a Series (older versions or specific cases)\n",
    "        feature_importances = mean_abs_shap_values\n",
    "\n",
    "    if not feature_importances.empty:\n",
    "        important_feature_name = feature_importances.idxmax() # Get the name of the most important feature\n",
    "        print(f\"\\nFeature Dependence Plot for most important feature: {important_feature_name}\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        # Use the feature name to index the Explanation object\n",
    "        shap.plots.scatter(shap_values_obj_test[:, important_feature_name], color=shap_values_obj_test, show=False)\n",
    "        plt.title(f\"SHAP Dependence Plot for {important_feature_name}\\n(Color indicates interaction with another feature)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Could not determine the most important feature to plot for dependence.\")\n",
    "else:\n",
    "    print(\"Could not calculate mean absolute SHAP values to determine the most important feature.\")\n",
    "\n",
    "# e. Force Plot\n",
    "# For a single instance (matplotlib version for scripts):\n",
    "if base_value is not None: # Ensure base_value was successfully retrieved\n",
    "    print(f\"\\nForce Plot for instance {instance_idx}:\")\n",
    "    plt.figure(figsize=(12,4)) # Force plots are typically wide\n",
    "    # shap.force_plot requires the base value, SHAP values (numpy array) for the instance,\n",
    "    # and feature values (pandas Series or DataFrame row) for the instance.\n",
    "    shap.force_plot(base_value,\n",
    "                    shap_values_obj_test.values[instance_idx,:],\n",
    "                    X_test.iloc[instance_idx,:],\n",
    "                    matplotlib=True, show=False) # matplotlib=True for static plot in scripts\n",
    "    plt.title(f\"SHAP Force Plot (Matplotlib) for Instance {instance_idx}\")\n",
    "    # plt.tight_layout() # tight_layout may not always work well with force_plot's fixed aspects\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot generate Force Plot because base_value is undefined.\")\n",
    "\n",
    "# To save an interactive Force Plot for multiple samples\n",
    "if base_value is not None:\n",
    "    print(\"\\nAttempting to generate and save an interactive Force Plot (first 100 samples)...\")\n",
    "    try:\n",
    "        # shap.force_plot for multiple samples generates JavaScript\n",
    "        force_plot_html = shap.force_plot(base_value,\n",
    "                                          shap_values_obj_test.values[:100,:], # SHAP values for first 100 samples\n",
    "                                          X_test.iloc[:100,:], # Feature values for first 100 samples\n",
    "                                          show=False)\n",
    "        shap.save_html(\"force_plot_multiple_samples.html\", force_plot_html)\n",
    "        print(\"Interactive Force Plot (multiple samples) saved to 'force_plot_multiple_samples.html'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate interactive Force Plot: {e}\")\n",
    "else:\n",
    "    print(\"Cannot generate multi-sample Force Plot because base_value is undefined.\")\n",
    "\n",
    "print(\"\\n--- SHAP Explainability Demo Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
